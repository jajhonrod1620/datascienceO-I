{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are the regions at the company complying with the forecast?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Business Context.** You work at O-I glass inc, the company is wondering how the compliance of the forecast is evolving in february in the regions in which it operates. The following are the regions that need to be analized.\n",
    "\n",
    "1. APAC.\n",
    "2. EU.\n",
    "3. Latin America.\n",
    "4. North America.\n",
    "\n",
    "Because the firm is quite large, good strategies to get the compliance of forecast are hard to come by. The leaders of the company are asking for insights related to compliance so they can come up with good strategies to get good results in all regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business Problem.**  your team lead asks you to investigate the following: **\"How is the compliance in each region?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analytical Context.** The data you've been given is in the Comma Separated Value (CSV) format, and comprises shipped quantities and tonnes for each of the forementioned regions. This case begins with a brief overview of this data, after which you will: (1) learn how to use the Python library ```pandas``` to load the data; (2) use ```pandas``` transform this data into a form amenable for analysis; and finally (3) use ```pandas``` to analyze the above question and come to a conclusion. As you may have guessed, ```pandas``` is an enormously useful library for data analysis and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages to aid in data analysis\n",
    "\n",
    "External libraries (a.k.a. packages) are code bases that contain a variety of pre-written functions and tools. This allows you to perform a variety of complex tasks in Python without having to \"reinvent the wheel\" build everything from the ground up. We will use two core packages: ```pandas``` and ```numpy```.\n",
    "\n",
    "```pandas``` is an external library that provides functionality for data analysis. Pandas specifically offers a variety of data structures and data manipulation methods that allow you to perform complex tasks with simple, one-line commands.\n",
    "\n",
    "```numpy``` is a package that we will use later in the case that offers numerous mathematical operations. Together, ```pandas``` and ```numpy``` allow you to create a data science workflow within Python.\n",
    "\n",
    "Let's import both packages using the ```import``` keyword. We will rename ```pandas``` to ```pd``` and ```numpy``` to ```np``` using the ```as``` keyword. This allows us to use the short name abbreviation when we want to reference any function that is inside either package. The abbreviations we chose are standard across the data science industry and should be followed unless there is a very, very good reason not to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Import the NumPy package\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that these packages are loaded into Python, we can use their contents. Let's first take a look at ```pandas``` as it has a variety of features we will use to load and analyze our stock data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentals of ```pandas```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At the core of the ```pandas``` library are two fundamental data structures/objects:\n",
    "1. ```Series```\n",
    "2. ```DataFrame```\n",
    "\n",
    "A ```Series``` object stores single-column data along with an **index**. An index is just a way of \"numbering\" the ```Series``` object. For example, in this case study, the indices will be dates, while the single-column data may be stock prices or daily trading volume.\n",
    "\n",
    "A ```DataFrame``` object is a two-dimensional tabular data structure with labeled axes. It is conceptually helpful to think of a DataFrame object as a collection of Series objects. Namely, think of each column in a DataFrame as a single Series object, where each of these Series objects shares a common index -  the index of the DataFrame object.\n",
    "\n",
    "Below is the syntax for creating a Series object, followed by the syntax for creating a DataFrame object. Note that DataFrame objects can also have a single-column â€“ think of this as a DataFrame consisting of a single Series object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0     1000\n1     2600\n2     1524\n3    98000\nName: Volume, dtype: int64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple Series object\n",
    "simple_series = pd.Series(index=[0,1,2,3], name='Volume', data=[1000,2600,1524,98000])\n",
    "simple_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing ```pd.Series``` to ```pd.DataFrame```, and adding a columns input list, a DataFrame object can be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>98000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   Volume\n0    1000\n1    2600\n2    1524\n3   98000"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple DataFrame object\n",
    "simple_df = pd.DataFrame(index=[0,1,2,3], columns=['Volume'], data=[1000,2600,1524,98000])\n",
    "simple_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame objects are more general compared to Series objects. Let's create a two column DataFrame object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>20190101</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>20190102</td>\n      <td>2600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>20190103</td>\n      <td>1524</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>20190104</td>\n      <td>98000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       Date  Volume\n0  20190101    1000\n1  20190102    2600\n2  20190103    1524\n3  20190104   98000"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create another DataFrame object\n",
    "another_df = pd.DataFrame(index=[0,1,2,3], columns=['Date','Volume'], data=[[20190101,1000],[20190102,2600],[20190103,1524],[20190104,98000]])\n",
    "another_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how a list of lists was used to specify the data in the ```another_df``` DataFrame. Each element of the list corresponds to a row in the DataFrame, so the list has 4 elements because there are 4 indices. Each element of the list of lists has 2 elements because the DataFrame has two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a file as a DataFrame and assign to df\n",
    "df = pd.read_csv('data/apac.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using <code>pandas</code> to analyze forecast data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Recall that we have CSV files that include data for each of the following O-I Glass regions:\n",
    "\n",
    "1. Asia Pacific.\n",
    "2. Europe.\n",
    "3. Latin America.\n",
    "4. North America.\n",
    "\n",
    "The available data for each region includes:\n",
    "\n",
    "1. **Calendar Day:** The shipment date, only includes february current dates\n",
    "2. **Region:** Region in which the tonnes were shipped\n",
    "3. **Commercial Forecast Tonnes:** The forecasted value of tonnes to be shipped\n",
    "4. **Shipped Quantity:** The actual quantity of units shipped\n",
    "5. **Shipped Tonnes:** The actual number of tonnes shipped\n",
    "\n",
    "To get a better sense of the available data, let's first take a look at just the data for OI, listed on the Asia Pacific file. You are given a CSV file that contains the company's shipment data, ```apac.csv```. Pandas allows easy loading of CSV files through the use of the method ```pd.read_csv()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2/1/2020</td>\n      <td>0.000000</td>\n      <td>502728</td>\n      <td>76.100</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2/2/2020</td>\n      <td>0.000000</td>\n      <td>3151926</td>\n      <td>569.794</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2/3/2020</td>\n      <td>3778.204283</td>\n      <td>12879518</td>\n      <td>3030.398</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2/4/2020</td>\n      <td>3773.625591</td>\n      <td>17563183</td>\n      <td>3959.278</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2/5/2020</td>\n      <td>3779.526197</td>\n      <td>16341120</td>\n      <td>3582.866</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes\n0     2/1/2020                    0.000000            502728          76.100\n1     2/2/2020                    0.000000           3151926         569.794\n2     2/3/2020                 3778.204283          12879518        3030.398\n3     2/4/2020                 3773.625591          17563183        3959.278\n4     2/5/2020                 3779.526197          16341120        3582.866"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the head of the DataFrame (i.e. the top rows of the DataFrame)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the file ```apac.csv``` are now stored in the DataFrame object ```df```.\n",
    "\n",
    "There are several common methods and attributes available to take a peek at the data and get a sense of it:\n",
    "\n",
    "1. ```DataFrame.head()```  -> returns the column names and first 5 rows by default\n",
    "2. ```DataFrame.tail()```  -> returns the column names and last 5 rows by default\n",
    "3. ```DataFrame.shape```   -> returns (num_rows, num_columns)\n",
    "4. ```DataFrame.columns``` -> returns index of columns\n",
    "5. ```DataFrame.index```   -> returns index of rows\n",
    "\n",
    "Using ```df.head()``` and ```df.tail()``` we can take a look at the data contents. Unless specified otherwise, Pandas Series and DataFrame objects have indicies starting at 0 and increase monotonically upward along the integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we see there are 19 data entries (each with 4 data points) for OI. The shape of a DataFrame is accessed using the ```shape``` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>14</td>\n      <td>2/15/2020</td>\n      <td>0.000000</td>\n      <td>4036324</td>\n      <td>884.4320</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2/16/2020</td>\n      <td>0.000000</td>\n      <td>4697999</td>\n      <td>858.9920</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2/17/2020</td>\n      <td>3779.526197</td>\n      <td>18806067</td>\n      <td>4598.8002</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2/18/2020</td>\n      <td>3770.926784</td>\n      <td>19919523</td>\n      <td>4739.5920</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2/19/2020</td>\n      <td>3779.526197</td>\n      <td>13055177</td>\n      <td>3182.6530</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes\n14    2/15/2020                    0.000000           4036324        884.4320\n15    2/16/2020                    0.000000           4697999        858.9920\n16    2/17/2020                 3779.526197          18806067       4598.8002\n17    2/18/2020                 3770.926784          19919523       4739.5920\n18    2/19/2020                 3779.526197          13055177       3182.6530"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the tail of the DataFrame (i.e. the top rows of the DataFrame)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(19, 4)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the shape of the two-dimensional structure, that is (num_rows, num_columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that ```DataFrame.columns``` and ```DataFrame.index``` return an index object instead of a list. To cast an index to a list for further list manipulation, we use the ```list()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['Calendar Day',\n 'Commercial Forecast Tonnes',\n 'Shipped Quantity',\n 'Shipped Tonnes']"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of the column names of the DataFrame\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of the column names of the DataFrame\n",
    "list(df.index)[0:20] # only showing first 20 index values so reduce screen output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating additional variables relevant to forecast compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes, the data provided to you will not be sufficient to achieve your goal. You may have to add additional variables or data features to assist you. Recall that our original question concerned the compliance within the different regions where the company operates. Therefore, our DataFrame must have features related to these quantities.\n",
    "\n",
    "It can be helpful to think about adding columns to DataFrames as adding adjacent columns one-by-one in Excel. Here is an example of how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n      <th>Region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2/1/2020</td>\n      <td>0.000000</td>\n      <td>502728</td>\n      <td>76.100</td>\n      <td>APAC</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2/2/2020</td>\n      <td>0.000000</td>\n      <td>3151926</td>\n      <td>569.794</td>\n      <td>APAC</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2/3/2020</td>\n      <td>3778.204283</td>\n      <td>12879518</td>\n      <td>3030.398</td>\n      <td>APAC</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2/4/2020</td>\n      <td>3773.625591</td>\n      <td>17563183</td>\n      <td>3959.278</td>\n      <td>APAC</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2/5/2020</td>\n      <td>3779.526197</td>\n      <td>16341120</td>\n      <td>3582.866</td>\n      <td>APAC</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                    0.000000            502728          76.100   \n1     2/2/2020                    0.000000           3151926         569.794   \n2     2/3/2020                 3778.204283          12879518        3030.398   \n3     2/4/2020                 3773.625591          17563183        3959.278   \n4     2/5/2020                 3779.526197          16341120        3582.866   \n\n  Region  \n0   APAC  \n1   APAC  \n2   APAC  \n3   APAC  \n4   APAC  "
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new column named \"Region\"\n",
    "df['Region'] = 'APAC'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0      76.100\n1     569.794\n2    3030.398\n3    3959.278\n4    3582.866\nName: Shipped Tonnes, dtype: float64"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can access a column by using [] brackets and the column name\n",
    "df['Shipped Tonnes'].head() # added .head() to suppress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n      <th>Region</th>\n      <th>Quantity_Thousands</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2/1/2020</td>\n      <td>0.000000</td>\n      <td>502728</td>\n      <td>76.100</td>\n      <td>APAC</td>\n      <td>502.728</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2/2/2020</td>\n      <td>0.000000</td>\n      <td>3151926</td>\n      <td>569.794</td>\n      <td>APAC</td>\n      <td>3151.926</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2/3/2020</td>\n      <td>3778.204283</td>\n      <td>12879518</td>\n      <td>3030.398</td>\n      <td>APAC</td>\n      <td>12879.518</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2/4/2020</td>\n      <td>3773.625591</td>\n      <td>17563183</td>\n      <td>3959.278</td>\n      <td>APAC</td>\n      <td>17563.183</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2/5/2020</td>\n      <td>3779.526197</td>\n      <td>16341120</td>\n      <td>3582.866</td>\n      <td>APAC</td>\n      <td>16341.120</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                    0.000000            502728          76.100   \n1     2/2/2020                    0.000000           3151926         569.794   \n2     2/3/2020                 3778.204283          12879518        3030.398   \n3     2/4/2020                 3773.625591          17563183        3959.278   \n4     2/5/2020                 3779.526197          16341120        3582.866   \n\n  Region  Quantity_Thousands  \n0   APAC             502.728  \n1   APAC            3151.926  \n2   APAC           12879.518  \n3   APAC           17563.183  \n4   APAC           16341.120  "
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new column named \"Quantity_Thousands\", which is calculated from the Shipped Quantity column currently in df\n",
    "df['Quantity_Thousands'] = df['Shipped Quantity'] / 1000.0 # divide every row in df['Shipped Quantity'] by 1 thousand, store in new column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(19, 6)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the updated DataFrame shape. Two new columns have been added.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, we need to have a feature in our DataFrame that is related to compliance. Because this currently does not exist, we must create it from the already available features. Recall that compliance is the division between the Shipped Tonnes and the Forecast, save the results in a new column called *Compliance* and print the dataframe head:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n      <th>Region</th>\n      <th>Quantity_Thousands</th>\n      <th>Compliance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>14</td>\n      <td>2/15/2020</td>\n      <td>0.000000</td>\n      <td>4036324</td>\n      <td>884.4320</td>\n      <td>APAC</td>\n      <td>4036.324</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2/16/2020</td>\n      <td>0.000000</td>\n      <td>4697999</td>\n      <td>858.9920</td>\n      <td>APAC</td>\n      <td>4697.999</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2/17/2020</td>\n      <td>3779.526197</td>\n      <td>18806067</td>\n      <td>4598.8002</td>\n      <td>APAC</td>\n      <td>18806.067</td>\n      <td>1.216766</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2/18/2020</td>\n      <td>3770.926784</td>\n      <td>19919523</td>\n      <td>4739.5920</td>\n      <td>APAC</td>\n      <td>19919.523</td>\n      <td>1.256877</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2/19/2020</td>\n      <td>3779.526197</td>\n      <td>13055177</td>\n      <td>3182.6530</td>\n      <td>APAC</td>\n      <td>13055.177</td>\n      <td>0.842077</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n14    2/15/2020                    0.000000           4036324        884.4320   \n15    2/16/2020                    0.000000           4697999        858.9920   \n16    2/17/2020                 3779.526197          18806067       4598.8002   \n17    2/18/2020                 3770.926784          19919523       4739.5920   \n18    2/19/2020                 3779.526197          13055177       3182.6530   \n\n   Region  Quantity_Thousands  Compliance  \n14   APAC            4036.324         inf  \n15   APAC            4697.999         inf  \n16   APAC           18806.067    1.216766  \n17   APAC           19919.523    1.256877  \n18   APAC           13055.177    0.842077  "
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code here\n",
    "df['Compliance'] = df['Shipped Tonnes'] / df['Commercial Forecast Tonnes']\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the power of ```pandas```. We can simply perform mathematical operations on columns of DataFrames just as if the DataFrames were single variables themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have features relevant to the original question, and can proceed to the analysis step. A common first step in data analysis is to learn about the distribution of the available data. We will do this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning about the data distribution through summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's aggregate summary statistics for the four regions of the company. Fortunately, the DataFrame and Series objects offer a myriad of data summary statistics methods:\n",
    "\n",
    "1. ```min()```\n",
    "2. ```median()```\n",
    "3. ```mean()```\n",
    "4. ```max()```\n",
    "5. ```quantile()```\n",
    "\n",
    "Below, each method is used on the ```Shipped Tonnes``` column. Notice how simple the functions are to apply to the DataFrame. Simply type the name of the DataFrame, followed by a ```.``` and then the method name you'd like to calculate. We've chosen to select a single column ```Shipped Tonnes``` from the DataFrame ```df```, but you could have just as easily called these methods on the full DataFrame rather than a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "76.1"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the minimum of the Shipped Tonnes column\n",
    "df['Shipped Tonnes'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3030.3979999999997"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the median of the Shipped Tonnes column\n",
    "df['Shipped Tonnes'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2559.627536842105"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average of the Shipped Tonnes column\n",
    "df['Shipped Tonnes'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4739.592000000001"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the maximum of the Shipped Tonnes column\n",
    "df['Shipped Tonnes'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd also like to explore the data distribution at a more granular level to see how the distribution looks beyond the simple summary statistics presented above. For this, we can use the ```quantile()``` method. The ```quantile()``` method will return the value which represents the given percentile of all the data under study (in this case, of the ```Shipped Tonnes``` data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "871.712"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the 25th percentile\n",
    "df['Shipped Tonnes'].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "3684.4965"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the 75th percentile\n",
    "df['Shipped Tonnes'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a more efficient method to quickly compute all of these summary statistics? Yes. One incredibly useful method that combines these summary statistics and also adds a couple others is the ```describe()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count      19.000000\nmean     2559.627537\nstd      1548.040267\nmin        76.100000\n25%       871.712000\n50%      3030.398000\n75%      3684.496500\nmax      4739.592000\nName: Shipped Tonnes, dtype: float64"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Shipped Tonnes'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "Determine the 25th, 50th, and 75th percentile for the ```Commercial Forecast Tonnes```and ```Shipped Quantity``` columns of ```df```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is indicated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.0\n3770.926784\n3,779.5261969999997\n4,367,161.5\n12879518.0\n16360951.0\n"
    }
   ],
   "source": [
    "# code here\n",
    "print (df['Commercial Forecast Tonnes'].quantile(0.25))\n",
    "print (df['Commercial Forecast Tonnes'].quantile(0.5))\n",
    "print (f\"{df['Commercial Forecast Tonnes'].quantile(0.75):,}\")\n",
    "print (f\"{df['Shipped Quantity'].quantile(0.25):,}\")\n",
    "print (df['Shipped Quantity'].quantile(0.5))\n",
    "print (df['Shipped Quantity'].quantile(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'1,234,567,890'"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = 1234567890\n",
    "f\"{number:,}\"\n",
    "'1,234,567,890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregating data from multiple regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So far, we've only been looking at data from one of our four regions. Let's go ahead and combine all four CSV files to analyze the four regions together. This will also reduce the amount of programming work required since the code will be shared across the four regions.\n",
    "\n",
    "One way to accomplish this aggregation task is to use the ```pd.concat()``` method from ```pandas```. An input into this method may be a list of DataFrames that you'd like to concatenate. We will use a for loop to loop over each region name, load the corresponding CSV file, and then append the result to a list which is later aggregated using ```pd.concat()```. Let's take a look at how this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Defining region names\n --- Start loop over regions --- \nProcessing Region: apac\nProcessing Region: eu\nProcessing Region: la\nProcessing Region: na\n --- Complete loop over regions --- \nAggregating Data\nCalculating Salient Features\nagg_df DataFrame shape (rows, columns): \n(76, 6)\nHead of agg_df DataFrame: \n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n      <th>Region</th>\n      <th>Compliance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2/1/2020</td>\n      <td>0.000000</td>\n      <td>502728.0</td>\n      <td>76.100</td>\n      <td>apac</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2/2/2020</td>\n      <td>0.000000</td>\n      <td>3151926.0</td>\n      <td>569.794</td>\n      <td>apac</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2/3/2020</td>\n      <td>3778.204283</td>\n      <td>12879518.0</td>\n      <td>3030.398</td>\n      <td>apac</td>\n      <td>0.802074</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2/4/2020</td>\n      <td>3773.625591</td>\n      <td>17563183.0</td>\n      <td>3959.278</td>\n      <td>apac</td>\n      <td>1.049197</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2/5/2020</td>\n      <td>3779.526197</td>\n      <td>16341120.0</td>\n      <td>3582.866</td>\n      <td>apac</td>\n      <td>0.947967</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                    0.000000          502728.0          76.100   \n1     2/2/2020                    0.000000         3151926.0         569.794   \n2     2/3/2020                 3778.204283        12879518.0        3030.398   \n3     2/4/2020                 3773.625591        17563183.0        3959.278   \n4     2/5/2020                 3779.526197        16341120.0        3582.866   \n\n  Region  Compliance  \n0   apac    0.000000  \n1   apac    0.000000  \n2   apac    0.802074  \n3   apac    1.049197  \n4   apac    0.947967  "
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load five csv files into one dataframe\n",
    "print(\"Defining region names\")\n",
    "regions_data_to_load = ['apac','eu','la','na']\n",
    "list_of_df = []\n",
    "\n",
    "# Loop over all regions names\n",
    "print(\" --- Start loop over regions --- \")\n",
    "for i in regions_data_to_load:\n",
    "    print(\"Processing Region: \" + i)\n",
    "    temp_df = pd.read_csv('data/'+i+'.csv')\n",
    "    temp_df['Region'] = i # ADD NEW COLUMN WITH REGION NAME TO DISTINGUISH IN FINAL DATAFRAME\n",
    "    list_of_df.append(temp_df)\n",
    "\n",
    "print(\" --- Complete loop over regions --- \")\n",
    "    \n",
    "# Combine into a single DataFrame by using concat\n",
    "print(\"Aggregating Data\")\n",
    "agg_df = pd.concat(list_of_df, axis=0)\n",
    "\n",
    "# Add salient statistics for Compliance\n",
    "print('Calculating Salient Features')\n",
    "\n",
    "agg_df['Compliance'] = (agg_df['Shipped Tonnes'] / agg_df['Commercial Forecast Tonnes'])\n",
    "agg_df['Compliance']=agg_df['Compliance'].replace(np.inf,0) #cuando hay divsion por cero\n",
    "\n",
    "print(\"agg_df DataFrame shape (rows, columns): \")\n",
    "print(agg_df.shape)\n",
    "\n",
    "print(\"Head of agg_df DataFrame: \")\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the for loop, we've aggregated and added the relevant features we identified in the previous section. We then printed the head of the aggregated DataFrame to have a peek at the format of the data, and we've also printed the shape of the DataFrame. This is to sanity check that our final DataFrame is roughly what we expect. Notice the aggregated DataFrame has the same number of columns as the original single region (APAC) data, however the number of rows have increased. This makes sense, because each additional region contains its own data entries. So, this passes our sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to reverse this process and extract the data relevant to a single stock symbol from the aggregated DataFrame ```agg_df```, we can do so using the ```==``` operator, which returns True when two objects contain the same value, and False otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n      <th>Region</th>\n      <th>Compliance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2/1/2020</td>\n      <td>6122.582160</td>\n      <td>17156234.0</td>\n      <td>4282.418072</td>\n      <td>la</td>\n      <td>0.699446</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2/2/2020</td>\n      <td>1768.405546</td>\n      <td>2872543.0</td>\n      <td>852.957793</td>\n      <td>la</td>\n      <td>0.482332</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2/3/2020</td>\n      <td>8708.353228</td>\n      <td>22246211.0</td>\n      <td>5453.518169</td>\n      <td>la</td>\n      <td>0.626240</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2/4/2020</td>\n      <td>8708.353228</td>\n      <td>27522634.0</td>\n      <td>7130.092596</td>\n      <td>la</td>\n      <td>0.818765</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2/5/2020</td>\n      <td>8708.353228</td>\n      <td>30240505.0</td>\n      <td>7652.357294</td>\n      <td>la</td>\n      <td>0.878738</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                 6122.582160        17156234.0     4282.418072   \n1     2/2/2020                 1768.405546         2872543.0      852.957793   \n2     2/3/2020                 8708.353228        22246211.0     5453.518169   \n3     2/4/2020                 8708.353228        27522634.0     7130.092596   \n4     2/5/2020                 8708.353228        30240505.0     7652.357294   \n\n  Region  Compliance  \n0     la    0.699446  \n1     la    0.482332  \n2     la    0.626240  \n3     la    0.818765  \n4     la    0.878738  "
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_LA_df = agg_df[agg_df['Region'] == 'la']\n",
    "region_LA_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the code block above, we've filtered out the rows that correspond to each region. Namely,\n",
    "\n",
    "```python\n",
    "agg_df['Region'] == 'la'\n",
    "```\n",
    "returns a boolean series of the same number of rows of ```agg_df```, where each value is ```True``` or ```False``` depending on whether a specific row's ```Region``` values is equal to ```'la'```.\n",
    "\n",
    "This row extraction technique will be useful to us later in this case when we perform analyses on each individual region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Write code to write a for loop to loop through each of the four regions, extract only the rows correpsonding to each region, and calculate and print the average ```Shipped Quantity``` value for each of the four regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** One possible solution is indicated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Region apac Ship Qty mean :  11,125,755.0\nRegion eu Ship Qty mean :  43,376,028.94736842\nRegion la Ship Qty mean :  25,502,723.736842107\nRegion na Ship Qty mean :  23,264,635.606315788\n"
    }
   ],
   "source": [
    "# code here\n",
    "region_list = ['apac','eu','la','na']\n",
    "\n",
    "for i in region_list:\n",
    "   # code here\n",
    "   print ('Region '+ i + ' Ship Qty mean : ', f\"{agg_df[agg_df['Region'] == i]['Shipped Quantity'].mean():,}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing each region Compliance levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```pandas``` offers the ability to group related rows of DataFrames according to the values of other rows. This useful feature is accomplished using the ```groupby()``` method.  Let's take a look and see how this can be used to group rows so that each group corresponds to a single region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002BB08A387C8>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the groupby() method, notice a DataFrameGroupBy object is returned\n",
    "agg_df.groupby('Region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, the ```DataFrameGroupBy``` object can be most readily thought of as containing a DataFrame object for every group (in this case, a DataFrame object for each region). Specifically, each item of the object is a tuple, containing the group identifier (in this case the Region), and the corresponding rows of the DataFrame that have that Region).\n",
    "\n",
    "Fortunately, ```pandas``` allows you to iterate over the groupby object to see what's inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "------ Loop Begins ------ \n<class 'tuple'>\napac\n  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                    0.000000          502728.0          76.100   \n1     2/2/2020                    0.000000         3151926.0         569.794   \n2     2/3/2020                 3778.204283        12879518.0        3030.398   \n3     2/4/2020                 3773.625591        17563183.0        3959.278   \n4     2/5/2020                 3779.526197        16341120.0        3582.866   \n\n  Region  Compliance  \n0   apac    0.000000  \n1   apac    0.000000  \n2   apac    0.802074  \n3   apac    1.049197  \n4   apac    0.947967  \n ------ Loop Ends ------ \n ------ Loop Begins ------ \n<class 'tuple'>\neu\n  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                     0.00000         2802197.0         790.578   \n1     2/2/2020                     0.00000         1266092.0         356.352   \n2     2/3/2020                 19700.18695        68743532.0       20446.802   \n3     2/4/2020                 19673.05295        67966277.0       20309.235   \n4     2/5/2020                 19720.31995        67118599.0       19545.794   \n\n  Region  Compliance  \n0     eu    0.000000  \n1     eu    0.000000  \n2     eu    1.037899  \n3     eu    1.032338  \n4     eu    0.991150  \n ------ Loop Ends ------ \n ------ Loop Begins ------ \n<class 'tuple'>\nla\n  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                 6122.582160        17156234.0     4282.418072   \n1     2/2/2020                 1768.405546         2872543.0      852.957793   \n2     2/3/2020                 8708.353228        22246211.0     5453.518169   \n3     2/4/2020                 8708.353228        27522634.0     7130.092596   \n4     2/5/2020                 8708.353228        30240505.0     7652.357294   \n\n  Region  Compliance  \n0     la    0.699446  \n1     la    0.482332  \n2     la    0.626240  \n3     la    0.818765  \n4     la    0.878738  \n ------ Loop Ends ------ \n ------ Loop Begins ------ \n<class 'tuple'>\nna\n  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                      0.0000        5430712.00     1180.392000   \n1     2/2/2020                      0.0000        2745530.00      623.319000   \n2     2/3/2020                  10197.6154       35329882.00     9348.106740   \n3     2/4/2020                  10160.2962       35234291.00     9505.032292   \n4     2/5/2020                  10197.6154       31119652.28     8509.721914   \n\n  Region  Compliance  \n0     na    0.000000  \n1     na    0.000000  \n2     na    0.916695  \n3     na    0.935507  \n4     na    0.834482  \n ------ Loop Ends ------ \n"
    }
   ],
   "source": [
    "grp_obj = agg_df.groupby('Region') # Group data in agg_df by Region\n",
    "\n",
    "# Loop through groups\n",
    "for item in grp_obj:\n",
    "    print(\" ------ Loop Begins ------ \")\n",
    "    print(type(item))     # Showing type of the item in grp_obj\n",
    "    print(item[0])        # Region\n",
    "    print(item[1].head()) # DataFrame with data for the Region\n",
    "    print(\" ------ Loop Ends ------ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine the ```pd.groupby()``` method with the ```describe()``` method and apply it to each region to analyze the distribution of compliance related features for each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "------Region:  apac\n       Compliance\ncount   19.000000\nmean     0.636228\nstd      0.470964\nmin      0.000000\n25%      0.000000\n50%      0.802074\n75%      0.987458\nmax      1.256877\n------Region:  eu\n       Compliance\ncount   19.000000\nmean     0.632874\nstd      0.498480\nmin      0.000000\n25%      0.000000\n50%      0.956403\n75%      1.029877\nmax      1.056820\n------Region:  la\n       Compliance\ncount   19.000000\nmean     0.948708\nstd      0.409703\nmin      0.045944\n25%      0.812527\n50%      0.924755\n75%      1.056716\nmax      2.006248\n------Region:  na\n       Compliance\ncount   19.000000\nmean     0.572496\nstd      0.456268\nmin      0.000000\n25%      0.000000\n50%      0.834482\n75%      0.918103\nmax      1.083643\n"
    }
   ],
   "source": [
    "grp_obj = agg_df.groupby('Region') # Group data in agg_df by Region\n",
    "\n",
    "# Loop through groups\n",
    "for item in grp_obj:\n",
    "    print('------Region: ', item[0])\n",
    "    grp_df = item[1]\n",
    "    relevant_df = grp_df[['Compliance']]\n",
    "    print(relevant_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One immediate observation of note is that the compliance level can vary widely and some regions tend to infinite. There are many reasons for this, a probable hypothesis is that we weren't expecting sales on these days but still got shipped tonnes.\n",
    "\n",
    "Another observation is that all regions got compliance levels over 80%.\n",
    "\n",
    "While this is great to see, there is a more powerful way to display this data in pandas. We can call the ```describe()``` method directly on the ```DataFrameGroupBy``` object. This one line allows you to avoid having to write a for loop every time you'd like to summarize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"8\" halign=\"left\">Compliance</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n    <tr>\n      <th>Region</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>apac</td>\n      <td>19.0</td>\n      <td>0.636228</td>\n      <td>0.470964</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.802074</td>\n      <td>0.987458</td>\n      <td>1.256877</td>\n    </tr>\n    <tr>\n      <td>eu</td>\n      <td>19.0</td>\n      <td>0.632874</td>\n      <td>0.498480</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.956403</td>\n      <td>1.029877</td>\n      <td>1.056820</td>\n    </tr>\n    <tr>\n      <td>la</td>\n      <td>19.0</td>\n      <td>0.948708</td>\n      <td>0.409703</td>\n      <td>0.045944</td>\n      <td>0.812527</td>\n      <td>0.924755</td>\n      <td>1.056716</td>\n      <td>2.006248</td>\n    </tr>\n    <tr>\n      <td>na</td>\n      <td>19.0</td>\n      <td>0.572496</td>\n      <td>0.456268</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.834482</td>\n      <td>0.918103</td>\n      <td>1.083643</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       Compliance                                                              \\\n            count      mean       std       min       25%       50%       75%   \nRegion                                                                          \napac         19.0  0.636228  0.470964  0.000000  0.000000  0.802074  0.987458   \neu           19.0  0.632874  0.498480  0.000000  0.000000  0.956403  1.029877   \nla           19.0  0.948708  0.409703  0.045944  0.812527  0.924755  1.056716   \nna           19.0  0.572496  0.456268  0.000000  0.000000  0.834482  0.918103   \n\n                  \n             max  \nRegion            \napac    1.256877  \neu      1.056820  \nla      2.006248  \nna      1.083643  "
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compliance\n",
    "agg_df[['Region','Compliance']].groupby('Region').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is identical to the data previously outputted using the for loop approach. The difference is that utilizing the features of the ```DataFrameGroupBy``` object allows for easy coding, fast results, and a clean output. This illustrates the power of using the ```pd.groupby()``` method: generating statistics for groups of interest in your data is straightforward and efficient to code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling data points as complying and not complying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've determined that the compliance levels of each region can vary widely per day, the next logical step is to group periods of complied, high compliance and low compliance to identify days with low compliance.\n",
    "\n",
    "However, we don't currently have a column that identifies when compliance is high and when it is low. Therefore, we must create a new column called ```Status``` using a threshold. For example, we'd like to have a new column value determined by:\n",
    "\n",
    "```\n",
    "\n",
    "if Compliance > treshold:\n",
    "    Status= 'High Compliance'\n",
    "else:\n",
    "    Status = 'Low Compliance'\n",
    "```\n",
    "\n",
    "Here we will define low compliance levels by any ```Compliance``` below the 50%th percentile. High compliance is over the 50%th percentile.\n",
    "Let's take a look how we can accomplish this task using ```groupby()``` functionality and the ```quantile()``` method, which returns the percentile for a given series of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Region\napac    0.802074\neu      0.956403\nla      0.924755\nna      0.834482\nName: Compliance, dtype: float64\n"
    }
   ],
   "source": [
    "# Determine lower thresholds for volatility for each symbol\n",
    "status_thresholds = agg_df.groupby('Region')['Compliance'].quantile(0.5) # 50th percentile (median)\n",
    "print(status_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'd like to label periods of high and low volatility by symbol, we will make use of the ```np.where()``` method in the ```numpy``` library. This method takes an input and checks a logical condition: if the condition is true, it will return its second argument, whereas if the condition is false, it will return its third argument. This is very similar to how Microsoft Excel's ```IFERROR()``` method works (helpful to think of it this way for those familiar with Excel). Let's loop through each symbol and label each day as either high and low volatility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Defining regions\n --- Loop over symbols --- \nLabelling compliance for region: apac\nLabelling compliance for region: eu\nLabelling compliance for region: la\nLabelling compliance for region: na\n --- Completed loop over regions --- \nAggregating data\n"
    }
   ],
   "source": [
    "# Loop through regions\n",
    "print(\"Defining regions\")\n",
    "list_of_regions= ['apac','eu','la','na']\n",
    "list_of_df = []\n",
    "\n",
    "# Loop over all regions\n",
    "print(\" --- Loop over symbols --- \")\n",
    "for i in list_of_regions:\n",
    "    print(\"Labelling compliance for region: \" + i)\n",
    "    temp_df = agg_df[agg_df['Region'] == i].copy() # make a copy of the dataframe to ensure not affecting agg_df\n",
    "    volstat_t = status_thresholds.loc[i]\n",
    "\n",
    "    temp_df['Status'] = np.where(temp_df['Compliance'] < volstat_t, 'Low Compliance', 'High Compliance') # Compliance label\n",
    "    list_of_df.append(temp_df)\n",
    "    \n",
    "print(\" --- Completed loop over regions --- \")\n",
    "\n",
    "print(\"Aggregating data\")\n",
    "labelled_df = pd.concat(list_of_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n      <th>Region</th>\n      <th>Compliance</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2/1/2020</td>\n      <td>0.000000</td>\n      <td>502728.0</td>\n      <td>76.100</td>\n      <td>apac</td>\n      <td>0.000000</td>\n      <td>Low Compliance</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2/2/2020</td>\n      <td>0.000000</td>\n      <td>3151926.0</td>\n      <td>569.794</td>\n      <td>apac</td>\n      <td>0.000000</td>\n      <td>Low Compliance</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2/3/2020</td>\n      <td>3778.204283</td>\n      <td>12879518.0</td>\n      <td>3030.398</td>\n      <td>apac</td>\n      <td>0.802074</td>\n      <td>High Compliance</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2/4/2020</td>\n      <td>3773.625591</td>\n      <td>17563183.0</td>\n      <td>3959.278</td>\n      <td>apac</td>\n      <td>1.049197</td>\n      <td>High Compliance</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2/5/2020</td>\n      <td>3779.526197</td>\n      <td>16341120.0</td>\n      <td>3582.866</td>\n      <td>apac</td>\n      <td>0.947967</td>\n      <td>High Compliance</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0     2/1/2020                    0.000000          502728.0          76.100   \n1     2/2/2020                    0.000000         3151926.0         569.794   \n2     2/3/2020                 3778.204283        12879518.0        3030.398   \n3     2/4/2020                 3773.625591        17563183.0        3959.278   \n4     2/5/2020                 3779.526197        16341120.0        3582.866   \n\n  Region  Compliance           Status  \n0   apac    0.000000   Low Compliance  \n1   apac    0.000000   Low Compliance  \n2   apac    0.802074  High Compliance  \n3   apac    1.049197  High Compliance  \n4   apac    0.947967  High Compliance  "
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now added a ```Status``` column that identifies whether each Region is in a period of high or low compliance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4:\n",
    "\n",
    "Write code to group regions into Low, Medium, or High compliance, where:\n",
    "\n",
    "```\n",
    "if Compliance > (75th percentile compliance for given region):\n",
    "    Status = 'HIGH'\n",
    "elif  Compliance > (25th percentile compliance for given region):\n",
    "    Status = 'MEDIUM'\n",
    "else:\n",
    "    Status = 'LOW'\n",
    "```\n",
    "\n",
    "Output a ```final_df``` DataFrame output grouped by Region, showing the mean Compliance for each Status category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Defining Regions\n --- Loop over Regions --- \nLabelling compliance for region: apac\nLabelling compliance for region: eu\nLabelling compliance for region: la\nLabelling compliance for region: na\n --- Completed loop over regions --- \nAggregating data\n               Compliance\nRegion Status            \napac   High      1.107213\n       Low       0.000000\n       Medium    0.819034\neu     High      1.045394\n       Low       0.000000\n       Medium    0.971092\nla     High      1.398977\n       Low       0.532050\n       Medium    0.930034\nna     High      0.995786\n       Low       0.000000\n       Medium    0.737312\n"
    }
   ],
   "source": [
    "# code here\n",
    "# Determine thresholds for compliance for each region\n",
    "compliance_thresholds_75 =  agg_df.groupby('Region')['Compliance'].quantile(0.75) \n",
    "compliance_thresholds_25 =  agg_df.groupby('Region')['Compliance'].quantile(0.25)\n",
    "\n",
    "# Loop through regions\n",
    "print(\"Defining Regions\")\n",
    "list_of_Regions= ['apac','eu','la','na']\n",
    "list_of_df = []\n",
    "\n",
    "# Loop over all regions\n",
    "print(\" --- Loop over Regions --- \")\n",
    "for i in list_of_Regions:\n",
    "   #code here\n",
    "   print(\"Labelling compliance for region: \" + i)\n",
    "   temp_df = agg_df[agg_df['Region'] == i].copy() # make a copy of the dataframe to ensure not affecting agg_df\n",
    "   volstat_t75 = compliance_thresholds_75.loc[i]\n",
    "   volstat_t25 = compliance_thresholds_25.loc[i]\n",
    "\n",
    "   temp_df['Status'] = np.where(temp_df['Compliance'] > volstat_t75, 'High', np.where(temp_df['Compliance'] > volstat_t25, 'Medium', 'Low')) # Compliance label\n",
    "   list_of_df.append(temp_df)\n",
    "    \n",
    "print(\" --- Completed loop over regions --- \")\n",
    "\n",
    "print(\"Aggregating data\")\n",
    "final_df = pd.concat(list_of_df)\n",
    "print \n",
    "print(final_df.groupby(['Region','Status'])[['Compliance']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calendar Day</th>\n      <th>Commercial Forecast Tonnes</th>\n      <th>Shipped Quantity</th>\n      <th>Shipped Tonnes</th>\n      <th>Region</th>\n      <th>Compliance</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2/1/2020</td>\n      <td>0.000000</td>\n      <td>502728.00</td>\n      <td>76.100000</td>\n      <td>apac</td>\n      <td>0.000000</td>\n      <td>Low Compliance</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2/2/2020</td>\n      <td>0.000000</td>\n      <td>3151926.00</td>\n      <td>569.794000</td>\n      <td>apac</td>\n      <td>0.000000</td>\n      <td>Low Compliance</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2/3/2020</td>\n      <td>3778.204283</td>\n      <td>12879518.00</td>\n      <td>3030.398000</td>\n      <td>apac</td>\n      <td>0.802074</td>\n      <td>High Compliance</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2/4/2020</td>\n      <td>3773.625591</td>\n      <td>17563183.00</td>\n      <td>3959.278000</td>\n      <td>apac</td>\n      <td>1.049197</td>\n      <td>High Compliance</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2/5/2020</td>\n      <td>3779.526197</td>\n      <td>16341120.00</td>\n      <td>3582.866000</td>\n      <td>apac</td>\n      <td>0.947967</td>\n      <td>High Compliance</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2/15/2020</td>\n      <td>0.000000</td>\n      <td>4482056.00</td>\n      <td>1008.661000</td>\n      <td>na</td>\n      <td>0.000000</td>\n      <td>Low Compliance</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2/16/2020</td>\n      <td>0.000000</td>\n      <td>3996734.00</td>\n      <td>829.000000</td>\n      <td>na</td>\n      <td>0.000000</td>\n      <td>Low Compliance</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2/17/2020</td>\n      <td>10175.615400</td>\n      <td>36457630.00</td>\n      <td>9255.214179</td>\n      <td>na</td>\n      <td>0.909548</td>\n      <td>High Compliance</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2/18/2020</td>\n      <td>10197.615400</td>\n      <td>42055901.77</td>\n      <td>10685.842690</td>\n      <td>na</td>\n      <td>1.047877</td>\n      <td>High Compliance</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2/19/2020</td>\n      <td>10197.615400</td>\n      <td>176000.00</td>\n      <td>33.154000</td>\n      <td>na</td>\n      <td>0.003251</td>\n      <td>Low Compliance</td>\n    </tr>\n  </tbody>\n</table>\n<p>76 rows Ã— 7 columns</p>\n</div>",
      "text/plain": "   Calendar Day  Commercial Forecast Tonnes  Shipped Quantity  Shipped Tonnes  \\\n0      2/1/2020                    0.000000         502728.00       76.100000   \n1      2/2/2020                    0.000000        3151926.00      569.794000   \n2      2/3/2020                 3778.204283       12879518.00     3030.398000   \n3      2/4/2020                 3773.625591       17563183.00     3959.278000   \n4      2/5/2020                 3779.526197       16341120.00     3582.866000   \n..          ...                         ...               ...             ...   \n14    2/15/2020                    0.000000        4482056.00     1008.661000   \n15    2/16/2020                    0.000000        3996734.00      829.000000   \n16    2/17/2020                10175.615400       36457630.00     9255.214179   \n17    2/18/2020                10197.615400       42055901.77    10685.842690   \n18    2/19/2020                10197.615400         176000.00       33.154000   \n\n   Region  Compliance           Status  \n0    apac    0.000000   Low Compliance  \n1    apac    0.000000   Low Compliance  \n2    apac    0.802074  High Compliance  \n3    apac    1.049197  High Compliance  \n4    apac    0.947967  High Compliance  \n..    ...         ...              ...  \n14     na    0.000000   Low Compliance  \n15     na    0.000000   Low Compliance  \n16     na    0.909548  High Compliance  \n17     na    1.047877  High Compliance  \n18     na    0.003251   Low Compliance  \n\n[76 rows x 7 columns]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "\n",
    "Write a script to find and print the day that has the highest shipped tonnes for each Region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.groupby.generic.DataFrameGroupBy'> \n\n\n------Region:  apac\n     Shipped Tonnes\nday                \n18         4739.592\n------Region:  eu\n     Shipped Tonnes\nday                \n11        20810.462\n------Region:  la\n     Shipped Tonnes\nday                \n12       9681.34499\n------Region:  na\n     Shipped Tonnes\nday                \n10      11050.57511\n"
    }
   ],
   "source": [
    "# code here\n",
    "\n",
    "# Add a column for the day\n",
    "day_list = []\n",
    "for i in agg_df['Calendar Day']:\n",
    "    day_list.append(i[2:4])\n",
    "    \n",
    "agg_df['day'] = day_list\n",
    "\n",
    "\n",
    "# Group by Region, then loop through the group object to group by day and calculate shipped tonnes\n",
    "# code here\n",
    "grp_obj = agg_df.groupby('Region')\n",
    "print(type(grp_obj), \"\\n\\n\")\n",
    "\n",
    "for item in grp_obj:    \n",
    "    print('------Region: ', item[0])\n",
    "    grp_df = item[1]\n",
    "    #grp_df.head()\n",
    "    relevant_df = grp_df[['day','Shipped Tonnes']]\n",
    "    #print(relevant_df)\n",
    "    day_df = relevant_df.groupby('day').sum()\n",
    "    \n",
    "    max_volume = float(day_df.max())\n",
    "    print(day_df[day_df['Shipped Tonnes'] == max_volume])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this case, we've learned the foundations of the ```pandas``` library in Python. We now know how to:\n",
    "\n",
    "1. Read data from files\n",
    "2. Aggregate and manipulate data using ```pandas```\n",
    "3. Analyze summary statistics and gather information from trends across time\n",
    "\n",
    "Going forward, we will be able to use ```pandas``` as a data analysis framework to build more complex projects and solve critical business problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Cheat Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://owensillinois.sharepoint.com/:b:/r/teams/DS4OI-One/Shared%20Documents/General/Resources/Data%20Wrangling%20with%20pandas%20.pdf?csf=1&e=s2fgrh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.w3resource.com/python-exercises/pandas/index.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas merging 101\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53645882/pandas-merging-101"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}